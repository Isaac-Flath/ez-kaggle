[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ez_kaggle",
    "section": "",
    "text": "from ez_kaggle.setup import *\nfrom ez_kaggle.dataset import *\nfrom ez_kaggle.kernel import *\nfrom pathlib import Path"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "ez_kaggle",
    "section": "Install",
    "text": "Install\npip install ez-kaggle"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "ez_kaggle",
    "section": "How to use",
    "text": "How to use\n\nCore\nThis little library is where I’ll be putting snippets of stuff which are useful on Kaggle. Functionality includes the following:\nIt defines IN_KAGGLE which is True if you’re running on Kaggle or False if you are not running on kaggle:\n\nIN_KAGGLE\n\nFalse\n\n\nYou can also use the kaggle api directly, even on kaggle with\n\napi = import_kaggle()\n\n\n\nCompetition\nThe competition module gives a setup_comp function which:\n\nGets a path to the data for a competition, downloading it if needed\ninstalls any modules that might be missing or out of data if running on Kaggle\nCreates a config file with the competition name, paths where datasets to be stored, username to use for datasets, and other competition configurable items\n\n\nNote: All config values have smart defaults that work for almost every competition. You don’t have to define any of them, but you’re welcome to change them if you’d like.\n\n\nsetup_comp('titanic')\n\nInferring dataset_username from credentials\nInferring model_dataset_name from competition\nInferring libraries_dataset_name from competition\nSetting required libraries to ['fastkaggle']\n\n\n\n\nLibraries\nThe Libraries module gives a function to manage pip libraries as kaggle datasets, especially useful for no-internet inference competitions\nSimply define list your pip requirements in the fastkaggle.json config file and call create_dependency_dataset anytime for it to create/update the dataset with the lastest of those packages in pip.\n\n\n\n\n\n\nTip\n\n\n\nThe purpose of this is to create datasets that can be used in no internet inference competitions to install libraries using pip install -Uqq library --no-index --find-links=file:///kaggle/input/your_dataset/\n\n\n\ncreate_dependency_dataset()\n\n-----Downloading or Creating Dataset if needed\n-----Checking dataset files against pip\n-----Kaggle dataset already up to date\nisaacflath/libraries-titanic update complete\n\n\n\n\nModels\nThe Models module gives functions to manage your models as kaggle datasets, especially useful for no-internet inference competitions\nSimply create and train your normal fastai model.\n\nfrom fastai.vision.all import *\nimport pandas as pd\n\nCreate a fastai model\n\npath = untar_data(URLs.MNIST_SAMPLE)\ndf = pd.read_csv(path/'labels.csv')\ndls = ImageDataLoaders.from_df(df,path)\nlearn = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), ps=0.25)\n\n[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n\n\nThen pass is to fastkaggle with a name a version comment for it to be exported and updated in your competition kaggle dataset (defined in fastkaggle.json config file)\n\npush_fastai_learner(learn,'model1.pkl','testing fastkaggle')\n\n-----Downloading or Creating Dataset if needed\nmodels-titanic\nisaacflath/models-titanic update complete\n\n\n\n\nNotebooks\nNotebooks can be pushed to kaggle kernels with push_notebook, and these notebooks can understand if they are running locally or in kaggle thanks to is_kaggle. No need to manage 2 environments, just work on your own machine and push anytime!\nThis function:\n\nInfers title using nbdev\nCreates Id by removing punctuation, whitespace and lowecasing title\nLinks you kaggle dataset with your libraries and your kaggle dataset with your models to it as defined in fastkaggle.json\n\n\npush_notebook('index.ipynb')\n\nKernel version 5 successfully pushed.  Please check progress at https://www.kaggle.com/code/isaacflath/ez-kaggle"
  },
  {
    "objectID": "dataset.html",
    "href": "dataset.html",
    "title": "ez_kaggle.dataset",
    "section": "",
    "text": "from fastcore.foundation import L"
  },
  {
    "objectID": "dataset.html#foundation",
    "href": "dataset.html#foundation",
    "title": "ez_kaggle.dataset",
    "section": "Foundation",
    "text": "Foundation\n\nsource\n\nds_exists\n\n ds_exists (dataset_slug, path='.')\n\nCheck if a dataset exists\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_slug\n\n\nDataset slug (ie “zillow/zecon”)\n\n\npath\nstr\n.\npath to fastkaggle.json file or None\n\n\n\n\nassert ds_exists('isaacflath/library-fastkaggle')\nassert not ds_exists('not/real/dataset')\n\n\nsource\n\n\nmk_dataset\n\n mk_dataset (dataset_path, title, force=False, upload=True, cfg_path='.',\n             **kwargs)\n\nCreates minimal dataset metadata needed to push new dataset to kaggle\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_path\n\n\nLocal path to create dataset in\n\n\ntitle\n\n\nName of the dataset\n\n\nforce\nbool\nFalse\nShould it overwrite or error if exists?\n\n\nupload\nbool\nTrue\nShould it upload and create on kaggle\n\n\ncfg_path\nstr\n.\npath to fastkaggle.json file or None\n\n\nkwargs\n\n\n\n\n\n\n\nmk_dataset('./testds','mytestds',force=True,upload=False)\npath = Path('./testds/dataset-metadata.json')\nmd = json.load(open(path))\nassert md['title'] == 'mytestds'\nassert md['id'].endswith('/mytestds')\npath.unlink()\npath.parent.rmdir()\n\nData package template written to: testds/dataset-metadata.json\n\n\n\nsource\n\n\nget_dataset\n\n get_dataset (dataset_slug, dataset_path, unzip=True, force=False)\n\nDownloads an existing dataset and metadata from kaggle\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_slug\n\n\nDataset slug (ie “zillow/zecon”)\n\n\ndataset_path\n\n\nLocal path to download dataset to\n\n\nunzip\nbool\nTrue\nShould it unzip after downloading?\n\n\nforce\nbool\nFalse\nShould it overwrite or error if dataset_path exists?\n\n\n\n\ndataset_path = Path('./data-science-job-salaries')\nget_dataset('ruchi798/data-science-job-salaries',dataset_path, force=True)\n\nfiles = os.listdir(dataset_path)\n\nassert L(files).sorted() == ['dataset-metadata.json', 'ds_salaries.csv']\n\nfor f in Path(dataset_path).ls(): f.unlink()\nPath(dataset_path).rmdir()\n\n\nsource\n\n\npush_dataset\n\n push_dataset (dataset_path, version_comment, quiet=True)\n\nPush dataset update to kaggle. Dataset path must contain dataset metadata file\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_path\n\n\nLocal path where dataset is stored\n\n\nversion_comment\n\n\nComment associated with this dataset update\n\n\nquiet\nbool\nTrue"
  },
  {
    "objectID": "dataset.html#pip-libraries",
    "href": "dataset.html#pip-libraries",
    "title": "ez_kaggle.dataset",
    "section": "Pip Libraries",
    "text": "Pip Libraries\n\nsource\n\nget_pip_library\n\n get_pip_library (pip_library, cfg_path='.', **kwargs)\n\nDownload the whl files for pip_library and store in dataset_path\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npip_library\n\n\nname of library for pip to install\n\n\ncfg_path\nstr\n.\npath to fastkaggle.json file or None\n\n\nkwargs\n\n\n\n\n\n\n\nlib = 'fastcore'\nget_pip_library(lib)\nassert Path(lib).exists()\nPath(lib).ls().map(lambda x: x.unlink())\nPath(lib).rmdir()\n\n\nsource\n\n\nget_pip_libraries\n\n get_pip_libraries (directory_name, cfg_path='.', **kwargs)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndirectory_name\n\n\n\n\n\ncfg_path\nstr\n.\npath to fastkaggle.json file or None\n\n\nkwargs\n\n\n\n\n\n\n\ndirectory_name = 'my-test-libs'\nget_pip_libraries('my-test-libs')\nassert Path(directory_name).exists()\nPath(directory_name).ls().map(lambda x: x.unlink())\nPath(directory_name).rmdir()\n\n\nsource\n\n\nget_local_ds_ver\n\n get_local_ds_ver (lib_path, lib)\n\nchecks a local copy of kaggle dataset for library version number\n\n\n\n\nDetails\n\n\n\n\nlib_path\nLocal path dataset is stored in\n\n\nlib\nName of library (ie “fastcore”)\n\n\n\n\nsource\n\n\ncreate_dependency_dataset\n\n create_dependency_dataset (version_notes='New Update', cfg_path='.',\n                            **kwargs)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nversion_notes\nstr\nNew Update\n\n\n\ncfg_path\nstr\n.\npath to fastkaggle.json file or None\n\n\nkwargs\n\n\n\n\n\n\n\ncreate_dependency_dataset()\npath = Path('libraries-titanic')\nassert path.exists()\nassert ds_exists('isaacflath/libraries-titanic')\nds_exists('isaacflath/libraries-titanic')\nPath(path).ls().map(lambda x: x.unlink())\nPath(path).rmdir()\n\n-----Downloading or Creating Dataset if needed\n-----Checking dataset files against pip\n-----Updating libraries-titanic in Kaggle\nisaacflath/libraries-titanic update complete"
  },
  {
    "objectID": "dataset.html#model-weights",
    "href": "dataset.html#model-weights",
    "title": "ez_kaggle.dataset",
    "section": "Model Weights",
    "text": "Model Weights\n\nsource\n\npush_fastai_learner\n\n push_fastai_learner (learner, model_fname, version_comment, cfg_path='.',\n                      **kwargs)\n\nExports a learner and updates kaggle dataset\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlearner\n\n\nFastai Learner\n\n\nmodel_fname\n\n\nie model1.pkl\n\n\nversion_comment\n\n\ndataset versioning\n\n\ncfg_path\nstr\n.\npath to fastkaggle.json file or None\n\n\nkwargs\n\n\n\n\n\n\n\nfrom fastai.vision.all import *\nimport pandas as pd\n\npath = untar_data(URLs.MNIST_SAMPLE)\ndf = pd.read_csv(path/'labels.csv')\ndls = ImageDataLoaders.from_df(df,path)\nlearn = vision_learner(dls, models.resnet18, loss_func=CrossEntropyLossFlat(), ps=0.25)\n\npush_fastai_learner(learn,'model1.pkl','testing fastkaggle')\n\npath = Path('models-titanic')\nassert path.exists()\nassert ds_exists('isaacflath/models-titanic')\nPath(path).ls().map(lambda x: x.unlink())\nPath(path).rmdir()\n\n[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n\n\n-----Downloading or Creating Dataset if needed\nmodels-titanic\nisaacflath/models-titanic update complete"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "ez_kaggle.setup",
    "section": "",
    "text": "source\n\n\n\n in_kaggle ()\n\nCheck if code is running in a kaggle kernel environment\n\nsource\n\n\n\n\n import_kaggle ()\n\nImport kaggle API, using Kaggle secrets kaggle_username and kaggle_key if needed\n\napi = import_kaggle()\nres = api.competitions_list(search='titanic')\nassert len(res) > 0\nprint(res)\n\n[spaceship-titanic, titanic]\n\n\n\nsource\n\n\n\n\n get_username ()"
  },
  {
    "objectID": "setup.html#competition",
    "href": "setup.html#competition",
    "title": "ez_kaggle.setup",
    "section": "Competition",
    "text": "Competition\n\nsource\n\nget_comp_data\n\n get_comp_data (competition)\n\nGet a path to data for competition, downloading it if needed\n\npath = get_comp_data('titanic')\nassert path == Path('titanic')\nassert path.exists()\nassert path.ls().sorted() == [Path('titanic/gender_submission.csv'),Path('titanic/test.csv'),Path('titanic/train.csv')]\n\n\nsource\n\n\ncompetition_config\n\n competition_config (competition, data_path=None, dataset_username=None,\n                     model_dataset_name=None, libraries_dataset_name=None,\n                     required_libraries=None, pip_cmd='pip')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncompetition\n\n\nie titanic\n\n\ndata_path\nNoneType\nNone\n\n\n\ndataset_username\nNoneType\nNone\nie isaacflath\n\n\nmodel_dataset_name\nNoneType\nNone\nie ‘models-pawpularity’\n\n\nlibraries_dataset_name\nNoneType\nNone\nie ‘libraries-pawpularity’\n\n\nrequired_libraries\nNoneType\nNone\nie [‘fastkaggle’,‘fastai’]\n\n\npip_cmd\nstr\npip\n\n\n\n\n\ncfg = competition_config('titanic')\ntest_eq(cfg.keys(),['competition', 'pip_cmd', 'data_path', 'datasets_username', 'model_dataset_name', 'libraries_dataset_name', 'required_libraries'])\nprint(json.dumps(cfg,indent=4))\n\nInferring dataset_username from credentials\nInferring model_dataset_name from competition\nInferring libraries_dataset_name from competition\nSetting required libraries to ['fastkaggle']\n{\n    \"competition\": \"titanic\",\n    \"pip_cmd\": \"pip\",\n    \"data_path\": null,\n    \"datasets_username\": \"isaacflath\",\n    \"model_dataset_name\": \"models-titanic\",\n    \"libraries_dataset_name\": \"libraries-titanic\",\n    \"required_libraries\": [\n        \"fastkaggle\"\n    ]\n}\n\n\n\nsource\n\n\nsetup_comp\n\n setup_comp (competition, dataset_username=None, model_dataset_name=None,\n             libraries_dataset_name=None, required_libraries=None,\n             pip_cmd='pip')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncompetition\n\n\nName of compeition\n\n\ndataset_username\nNoneType\nNone\nusername where datasets will be stored\n\n\nmodel_dataset_name\nNoneType\nNone\nname to store model weights\n\n\nlibraries_dataset_name\nNoneType\nNone\nname to store libraries\n\n\nrequired_libraries\nNoneType\nNone\nneeded libraries for competition\n\n\npip_cmd\nstr\npip\npip command to use for installation\n\n\n\n\nsetup_comp('titanic')\nassert Path('fastkaggle.json').exists()\n\nInferring dataset_username from credentials\nInferring model_dataset_name from competition\nInferring libraries_dataset_name from competition\nSetting required libraries to ['fastkaggle']\n\n\n\nsource\n\n\nget_config_values\n\n get_config_values (path='.', **cfg_overrides)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n.\npath to kaggle.json file or None\n\n\ncfg_overrides\n\n\n\n\n\n\n\ncfg = get_config_values() \ntest_eq(cfg.keys(),['competition', 'pip_cmd', 'data_path', 'datasets_username', 'model_dataset_name', 'libraries_dataset_name', 'required_libraries'])\nprint(json.dumps(cfg,indent=4))\n\n{\n    \"competition\": \"titanic\",\n    \"pip_cmd\": \"pip\",\n    \"data_path\": \".\",\n    \"datasets_username\": \"isaacflath\",\n    \"model_dataset_name\": \"models-titanic\",\n    \"libraries_dataset_name\": \"libraries-titanic\",\n    \"required_libraries\": [\n        \"fastkaggle\"\n    ]\n}\n\n\n\ncfg = get_config_values(competition=123,pip_cmd=4) \nprint(json.dumps(cfg,indent=4))\n\n{\n    \"competition\": 123,\n    \"pip_cmd\": 4,\n    \"data_path\": \".\",\n    \"datasets_username\": \"isaacflath\",\n    \"model_dataset_name\": \"models-titanic\",\n    \"libraries_dataset_name\": \"libraries-titanic\",\n    \"required_libraries\": [\n        \"fastkaggle\"\n    ]\n}"
  },
  {
    "objectID": "kernel.html",
    "href": "kernel.html",
    "title": "ez_kaggle.kernel",
    "section": "",
    "text": "source\n\nnb2names\n\n nb2names (file)\n\n\nnb2names('index.ipynb')\n\n('ez_kaggle', 'ez-kaggle')\n\n\nIf you pass a list of space separated modules to install, they’ll be installed if running on Kaggle.\n\nsource\n\n\nnb_meta\n\n nb_meta (file, private=False, gpu=False, internet=True,\n          language='python', cfg_path='.', **kwargs)\n\nGet the dict required for a kernel-metadata.json file\n\nmeta_new = nb_meta('index.ipynb')\n\n\nsource\n\n\npush_notebook\n\n push_notebook (file, cfg_path='.', private=False, gpu=True,\n                internet=True, **kwargs)\n\nPush notebook file to Kaggle Notebooks\n\npush_notebook('index.ipynb')\n\nKernel version 3 successfully pushed.  Please check progress at https://www.kaggle.com/code/isaacflath/ez-kaggle"
  }
]